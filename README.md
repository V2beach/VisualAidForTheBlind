# VisualAidForTheBlind
*Visual Aid For The Blind* Based On **Image Caption** And **VQA**

/NativeApp is Android code of the client
<br>
/CoreModel is Flask + Pytorch code of the server
<br>
/Else is consist of ppt for defense and demo

# References
- [Image Captioning](https://arxiv.org/abs/1502.03044)
- [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](https://arxiv.org/abs/1707.07998)
- [Deep Modular Co-Attention Networks for Visual Question Answering](https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Deep_Modular_Co-Attention_Networks_for_Visual_Question_Answering_CVPR_2019_paper.html)
